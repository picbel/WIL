// Metadata:
:description: Week I Learnt
:keywords: study, til, lwil
// Settings:
:doctype: book
:toc: left
:toclevels: 4
:sectlinks:
:icons: font
:hardbreaks:

---
https://github.com/picbel/WIL/blob/main/2025/04/wil.adoc[이전 달]

[[section-202505]]
== 2025년 5월

[[section-202505-1일]]
1일
===
### 헤이즐캐스트 (Hazelcast)

헤이즐캐스트는 **분산 인메모리 데이터 그리드(IMDG)**로, 분산 환경에서 고속의 데이터 저장 및 처리를 지원하는 플랫폼이다. 

- 각 노드는 메모리에 데이터를 저장하며, 데이터는 파티셔닝(분할)되어 클러스터 전체에 분산된다.
- 노드 간 통신은 TCP 기반으로 이뤄지며, 특정 키에 대한 데이터는 해시 기반으로 정해진 노드에 저장된다. 
- 각 파티션은 하나 이상의 백업 노드를 가질 수 있어, 장애 발생 시 자동 페일오버가 가능하도록 설계되어 있다.

Hazelcast는 캐시로도 사용 가능하며, Map, Queue, Topic, Lock, ExecutorService 등 다양한 분산 자료구조와 연산 기능을 제공합니다.

---

[[section-202505-3일]]
3일
===
### 하이브리드 암호화란?
하이브리드 암호화는 대칭키 암호화와 비대칭키 암호화의 장점을 조합한 방식이다.

|===
| 암호 방식 | 특징 | 장점 | 단점
| **대칭키 암호화** | 같은 키로 암호화/복호화 | 빠름, 효율적 | 키 전달이 어려움
| **비대칭키 암호화** | 공개키로 암호화, 개인키로 복호화 | 키 공유 쉬움 | 느리고 계산 비용 큼
|===

**하이브리드 암호화는 대칭키로 실제 데이터를 암호화하고, 대칭키 자체는 수신자의 공개키로 암호화하여 전송한다.**

동작 예시 - 클라이언트 → 서버로 보안을 유지하면서 데이터를 보낼 때:
하이브리드 암호화 순서

1. 클라이언트가 랜덤한 대칭키(예: AES 키) 생성
2. 전송할 데이터를 AES 대칭키로 암호화
3. AES 대칭키를 서버의 공개키(RSA 등)로 암호화
4. 암호화된 데이터 + 암호화된 AES키를 함께 전송
5. 서버는 개인키로 AES키 복호화, 이 AES키로 실제 데이터를 복호화

대표 사용 예시 - HTTPS
HTTPS도 하이브리드 암호화의 대표적인 예
초기 TLS Handshake에서 대칭키(세션키)를 협상하고, 이후 데이터 통신은 빠른 대칭키 방식으로 진행한다.

---

[[section-202505-5일]]
5일
===
### 순차(Sequential) I/O, 랜덤(Random) I/O

HDD를 기준으로 설명함

#### 랜덤(Random) I/O
**데이터를 임의의 순서로 접근(읽기/쓰기)하는 방식**
HDD에서는 데이터가 물리적으로 서로 떨어진 위치에 존재하므로, 디스크 헤드가 매번 해당 위치로 이동해야 한다.

예를 들어, 100개의 데이터를 랜덤하게 읽는다면 디스크 헤드는 최대 100번 이동해야 하며, 이에 따라 **탐색 시간(Seek Time)**과 **회전 지연(Rotational Latency)**이 누적되어 전체 처리 속도가 매우 느려진다.
또한, 각 데이터 접근마다 시스템 콜이 발생하여 커널 전환 비용도 증가한다.

#### 순차(Sequential) I/O
**데이터를 연속적으로(논리적, 물리적으로) 접근하는 방식**
일반적으로 파일을 처음부터 끝까지 순서대로 읽거나 쓰는 작업이 이에 해당한다.

순차 접근은 디스크 헤드가 한 번만 위치를 맞춘 후, 그 다음 데이터들을 연속적으로 처리할 수 있어 매우 효율적이다.
논리 주소가 연속되어 있으면, 매핑 테이블을 한 번만 조회한 뒤 물리적 주소를 연속적으로 따라갈 수 있으므로, I/O 요청 횟수 및 매핑 비용이 크게 줄어든다.
예를 들어, 100개의 데이터를 순차적으로 읽는 경우, 1번의 시스템 콜과 1번의 디스크 탐색만으로 모두 처리 가능하다.

추가 설명

- SSD에서는 디스크 헤드가 없기 때문에 랜덤 I/O와 순차 I/O의 성능 차이가 줄어든다. 하지만 여전히 순차 I/O가 더 빠르며, 시스템 캐시나 내부 병렬 처리 구조에서 유리하게 작용함.
- DB에서의 클러스터링 인덱스는 순차 I/O를 유도하여 범위 쿼리 성능을 최적화한다.
- Kafka의 로그 구조도 순차 쓰기를 통해 디스크 I/O 성능을 극대화하며, 대용량 데이터 처리에 유리한 구조이다.

[cols="1,1,1", options="header"]
|===
| 항목
| 랜덤 I/O
| 순차 I/O

| 디스크 헤드 이동
| 매 접근마다 이동 → 느림
| 처음 한 번만 이동 → 빠름

| 시스템 콜 횟수
| 데이터 수만큼 발생
| 1회 혹은 최소 횟수

| 성능
| 느림 (I/O 병목 원인)
| 빠름 (고속 처리 가능)

| 논리-물리 주소 매핑
| 매번 매핑 필요
| 최초 1회 매핑 후 연속 처리 가능

| 사용 예
| Secondary Index Scan, OLTP 트랜잭션 처리
| Clustering Index, Kafka 로그 저장, 파일 일괄 처리
|===


---

[[section-202505-8일]]
8일
===
### Thread vs supplyAsync 비교

자바의 비동기를 위한 쓰레드 객체 사용법

#### Thread
```java
Thread t = new Thread(() -> {
    // 작업 수행
});
t.start();
```

특징
- 직접 쓰레드 객체를 생성하고 실행 (start() 호출 필수)
- 개발자가 쓰레드 생성 및 생명주기 제어에 관여해야 함
- 재사용 불가, 매번 새 쓰레드 생성
- 리턴값 없음 (Runnable 기반)

사용 예시
- 아주 단순한 비동기 작업
- 일회성 백그라운드 작업

#### CompletableFuture.supplyAsync

```java
CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {
    // 작업 수행 후 결과 반환
    return "결과";
});

```

특징
- **쓰레드 풀(ForkJoinPool.commonPool)**을 내부적으로 사용 (재사용 가능)
- 비동기 실행 + 결과 반환 가능 (Supplier 기반)
- 체이닝 지원 (thenApply, thenAccept, exceptionally 등으로 조합 가능)
- 작업이 예외 발생시 .handle, .exceptionally 등으로 처리 가능

사용 예시
- 비동기 작업 결과가 필요한 경우 (예: API 호출, 계산)
- 비동기 흐름 제어 및 예외 처리 필요 시
- 작업 체이닝으로 복잡한 비동기 로직 구성할 때

요약
CompletableFuture.supplyAsync()와 new Thread()의 **가장 본질적인 차이점은 "쓰레드 풀 사용 여부"**
[cols="1,1,1", options="header"]
|===
| 항목
| `new Thread()`
| `CompletableFuture.supplyAsync()`

| 쓰레드 재사용
| 매번 새로 생성됨
| 쓰레드풀에서 꺼내 사용

| 리소스 효율
| 비효율적 (과도한 쓰레드 생성 위험)
| 효율적 (풀로 관리됨)

| 확장성
| 낮음 (많아지면 OOM 가능)
| 높음 (풀 크기 조절 가능)

| 기능 확장성 (체이닝, 예외처리 등)
| 없음
| 많음 (`then`, `handle` 등)
|===

---

### 스레드 풀 포화 정책(Saturation Policies)

ThreadPoolExecutor을 기준 스레드 풀 포화 정책이란 스레드풀이 포화상태인 경우 행동을 결정하는 정책을 의미한다
다음 기준이 충족되면 포화상태라 정의된다
- 상시 유지하는 스레드의 수인 corePoolSize
- 작업 대기열 크기인 workQueueSize
- 스레드를 추가할 수 있는 최대 수인 maxPoolSize
즉 corePoolSize, workQueueSize. maxPoolSize가 전부 꽉 찬상태 즉 스레드를 최대로 생성한 후에도 실행중인 스레드, 대기열까지 전부 다 차면 포화상태로 정의된다.
이렇게 포화 상태가 되었을때 새로운 요청이 오면 포화 정책이 실행된다. 포화 정책은 RejectedExecutionHandler 의 구현체에서 정의된다.

#### RejectedExecutionHandler
기본적으로 제공되는 RejectedExecutionHandler의 구현체는 4가지이다.
- AbortPolicy: RejectedExecutionException을 발생시킨다.
- DiscardPolicy: 신규 요청을 무시한다.
- DiscardOldestPolicy: 작업 대기열에서 가장 오래된 요청을 버리고 신규 요청을 대기열에 추가한다.
- CallerRunsPolicy: 요청 스레드에서 해당 작업을 실행한다.
혹은 RejectedExecutionHandler 인터페이스를 구현하여 커스텀 포화 정책을 만들 수 있다.

---

[[section-202505-9일]]
9일
===
### 커버링 인덱스(Covering Index)
쿼리가 참조하는 **모든 컬럼이 하나의 인덱스**에 포함되어 있는 경우를 커버링 인덱스이라 한다.
예를 들어 SELECT, WHERE, JOIN, ORDER BY 절 등에서 사용된 컬럼들이 전부 인덱스에 존재한다면, DB 엔진은 데이터 테이블(Heap)에 접근하지 않고 인덱스만으로 결과를 반환할 수 있다.
이런 경우 **"인덱스 온리 스캔(Index Only Scan)"**이 발생하며, 물리적인 I/O를 줄여 성능을 크게 개선할 수 있다.

```sql
CREATE INDEX idx_user_email_name ON users(email, name);

-- 아래 쿼리는 covering index가 적용될 수 있음
SELECT name FROM users WHERE email = 'user@example.com';
```
커버링 인덱스를 만들 때는 조회 빈도, 컬럼 수, DML 비율 등을 종합적으로 고려해야 한다.

> MySql에서 쿼리 실행계획(EXPLAIN)으로 확인시
> Extra에 Using index가 있고 Using where 또는 Using index condition이 없는 경우에는 커버링인덱스가 적용된것으로 추측하면된다.

커버링 인덱스도 결국 인덱스에 기반하여 만들어진 쿼리이다
장단점이 인덱스하고 공유된다

커버링 인덱스 장단점 요약 표
[options="header"]
|===
| 구분 | 항목 | 설명

| 장점
| 빠른 성능
| 테이블 접근 없이 인덱스만으로 결과를 조회하여 응답 속도가 빠름

| 
| I/O 감소
| 랜덤 디스크 접근을 줄여 디스크/CPU 부하 감소

| 
| 실행 계획 최적화
| 옵티마이저가 인덱스 온리 스캔을 선택해 더 효율적인 실행 계획 가능

| 단점
| 인덱스 크기 증가
| 많은 컬럼 포함으로 인해 인덱스가 비대해지고 저장 공간 증가

| 
| DML 성능 저하
| INSERT, UPDATE, DELETE 시 인덱스 갱신 비용이 증가

| 
| 관리 복잡도
| 쿼리 구조가 변경되면 인덱스도 자주 수정해야 하며 관리 비용 상승
|===

주의!
```sql
CREATE INDEX idx_ab ON tbl(a,b);
CREATE INDEX idx_c ON tbl(c);

EXPLAIN SELECT a, b FROM tbl WHERE c = 1;
```
인덱스가 [a,b], [c]처럼 분리되어 있고, WHERE c = 1 조건과 SELECT a, b를 사용하는 쿼리는 하나의 인덱스만으로 조건 + 출력 컬럼을 모두 커버할 수 없으므로, 커버링 인덱스가 아니다. 


---

[[section-202505-15일]]
15일
===
### Kafka에서 exactly-once 보장하는 법




---

[[section-202505-17일]]
17일
===
### Kafka의 특징: Sequential I/O, Zero copy, Consumer pull model

#### Sequential I/O
Kafka는 데이터를 저장할 때 append-only 방식으로 로그에 기록한다.
이 구조 덕분에 데이터를 디스크에 순차적으로 접근할 수 있으며, 디스크 탐색(Seek)이 최소화된다. 
따라서 HDD를 사용하더라도 높은 처리 속도를 유지할 수 있다.

#### Zero Copy
일반적으로 디스크에서 데이터를 읽어 네트워크로 전송할 경우, `디스크 버퍼 → OS 커널 버퍼 → 애플리케이션 버퍼 → I/O 버퍼 → 소켓 버퍼`c와 같은 복잡한 복사 과정을 거칩니다. Kafka는 Zero Copy 기술(주로 sendfile() 시스템 콜 활용)을 활용하여 애플리케이션 버퍼로의 데이터 복사를 생략하고, `디스크 버퍼 → OS 커널 버퍼 → 소켓 버퍼` 순으로 복사 단계를 줄여, 불필요한 복사를 줄이고 전송 속도를 향상시킨다.

#### Pull 기반 구조
Kafka는 컨슈머가 데이터를 직접 Pull하는 구조이다. 
이는 컨슈머가 자신의 처리 가능량에 맞춰 데이터를 가져오도록 하여, Back Pressure를 자연스럽게 제어할 수 있다. 
그 결과, 보다 안정적인 소비 처리가 가능하다.

---

[[section-202505-26일]]
26일
===
전문 검색 기능
