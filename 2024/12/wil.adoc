// Metadata:
:description: Week I Learnt
:keywords: study, til, lwil
// Settings:
:doctype: book
:toc: left
:toclevels: 4
:sectlinks:
:icons: font
:hardbreaks:


[[section-202412]]
== 2024년 12월

[[section-202412-2일]]
2일
===
### TransactionManager 와 Kotlin Coroutine

org.springframework:spring-tx 의 org.springframework.transaction.annotation.Transactinal 의 주석내용
```
* <h3>Transaction Management</h3>
*
* <p>This annotation commonly works with thread-bound transactions managed by a
* {@link org.springframework.transaction.PlatformTransactionManager}, exposing a
* transaction to all data access operations within the current execution thread.
* <b>Note: This does NOT propagate to newly started threads within the method.</b>
*
* <p>Alternatively, this annotation may demarcate a reactive transaction managed
* by a {@link org.springframework.transaction.ReactiveTransactionManager} which
* uses the Reactor context instead of thread-local variables. As a consequence,
* all participating data access operations need to execute within the same
* Reactor context in the same reactive pipeline.
```
위 주석내용을 간단히 요약하면 다음과 같다.

#### PlatformTransactionManager
Thread Local


#### ReactiveTransactionManager
Reactor Context



Spring Data에서 reactor와 코틀린 코루틴을 활용하여 CoroutineCrudRepository를 지원하기도 한다
data에 crud행위를 추상화한 인터페이스인 CrudRepository처럼 코루틴으로 data에 crud행위를 추상화한 인터페이스이다.


https://docs.spring.io/spring-data/relational/reference/kotlin/coroutines.html

---

[[section-202412-4일]]
4일
===
### ALPN
https://datatracker.ietf.org/doc/html/rfc7301
Http 프로토콜을 정하기위한 협상 과정
ALPN은 TLS 핸드셰이크 과정에서 클라이언트와 서버가 사용할 애플리케이션 프로토콜을 협상하기 위한 확장이다. HTTPS/2와 같은 프로토콜에서 사용된다.

**동작원리**
클라이언트 측: 클라이언트는 TLS 핸드셰이크 요청 시 자신이 지원하는 애플리케이션 프로토콜 목록을 ALPN 확장 필드에 포함시킨다.
서버 측: 서버는 클라이언트의 프로토콜 목록을 확인한 뒤, 자신이 지원하는 프로토콜 중 하나를 선택해 응답한다.
결과: 선택된 프로토콜이 TLS 핸드셰이크가 완료된 이후 애플리케이션 계층에서 사용된다.

기존 TLS 핸드셰이크에 통합되어 별도 요청 없이 최적화된 연결을 제공한다. 클라이언트와 서버가 공통 프로토콜을 지원하지 않으면 협상이 실패할 수 있다.

---

[[section-202412-9일]]
9일
===
### 벌크헤드 패턴
벌크헤드 패턴은 애플리케이션의 리소스를 격리하여 장애가 특정 부분에서만 발생하도록 제한하는 아키텍처 패턴이다. 
(선박의 방수 격벽(bulkhead) 개념에서 유래한 것으로, 한 구역에 물이 들어와도 다른 구역으로 확산되지 않도록 설계된 원리와 유사하다.)

핵심 개념
- 시스템 리소스를 독립된 구역으로 나눈다
- 특정 구역에서 장애가 발생해도 다른 구역은 정상적으로 동작한다.
- 장애 확산을 방지하고 전체 시스템의 가용성을 높이는데 기여한다.

예시
- 쓰레드풀 격리: 서비스마다 별도의 쓰레드풀을 할당하여 특정 서비스 과부하가 전체 쓰레드풀의 영향을 주지 않도록한다.
- 데이터 베이스 커넥션풀 분리: 서비스별로 데이터베이스 커넥션 풀을 사용해 리소스 고갈 방지
- API 요청 분리: 외부 API호출에 대해 격리된 시간 초과와 재시도 정책을 설정

적용 사례
- 마이크로서비스 아키텍처 (MSA): 각 서비스가 독립적으로 운영될 수 있도록 설계.
- 클라우드 기반 시스템: 다양한 리소스의 동적 관리 및 장애 전파 방지.

---

[[section-202412-12일]]
12일
===
### 서킷브레이커 (Circuit Breaker)
서킷 브레이커 패턴은 시스템에서 장애 확산을 방지하고 복구를 지원하기 위해 사용하는 보호 메커니즘이다. 
(전기회로 차단기의 개념에서 유래했으며, 서비스 간 호출 실패가 계속될 경우 요청을 차단해 시스템 과부하를 막는다.)

핵심 개념
- Closed 상태: 요청이 정상적으로 처리되는 상태. 호출은 계속 전달된다.
- Open 상태: 호출 실패가 일정 임계치를 초과하면 회로를 열어 추가 요청을 차단한다.
- Half-Open 상태: 일정 시간 후 일부 요청을 다시 시도해 시스템 복구 여부를 테스트한다.

장점
- 장애 확산 방지: 문제가 있는 서비스로의 호출을 중단해 전체 시스템에 미치는 영향을 최소화
- 시스템 안정성 향상: 실패한 서비스에 대한 불필요한 재시도를 방지해 리소스를 보호
- 빠른 복구 지원: 시스템 상태를 모니터링하며 정상화되면 호출을 재개

구현 예시
- Threshold 설정: 일정 횟수의 실패가 발생하면 서킷을 Open 상태로 전환.
- Timeout 설정: Open 상태 유지 시간 이후, Half-Open 상태로 전환해 복구 여부를 확인.
- Fallback 처리: 호출 실패 시 대체 로직 또는 기본 응답을 제공.

---

[[section-202412-18일]]
18일
===
### Java 쓰레드 풀의 active count
`ThreadPoolExecutor` 클래스의 `getActiveCount()` 메서드는 현재 작업을 수행 중인 쓰레드의 수를 반환한다.
만약 `Executors.newFixedThreadPool(n)`로 쓰레드 풀을 생성한 경우, `ThreadPoolExecutor`로 타입 변환해야 `getActiveCount()`를 사용할 수 있다.

---
[[section-202412-19일]]
19일
===
### 코틀린 코루틴 디스패처

#### **`Dispatchers.Default`**
   - CPU 집약적인 작업에 적합.
   - 공유된 스레드 풀에서 실행.
   - 스레드 풀 크기 : CPU 코어 갯수
   - 내부에서 싱글톤으로 디스페쳐가 선언되어있고 생성시 createScheduler()를 통해 스케줄러를 생성한 상태
```kotlin
// Instance of Dispatchers.Default
internal object DefaultScheduler : SchedulerCoroutineDispatcher(
   CORE_POOL_SIZE, MAX_POOL_SIZE,
   IDLE_WORKER_KEEP_ALIVE_NS, DEFAULT_SCHEDULER_NAME
)

// SchedulerCoroutineDispatcher의 내부에서 CoroutineScheduler를 생성해서 executor로 활용한다.
internal open class SchedulerCoroutineDispatcher(
    private val corePoolSize: Int = CORE_POOL_SIZE,
    private val maxPoolSize: Int = MAX_POOL_SIZE,
    private val idleWorkerKeepAliveNs: Long = IDLE_WORKER_KEEP_ALIVE_NS,
    private val schedulerName: String = "CoroutineScheduler",
) : ExecutorCoroutineDispatcher() {

    override val executor: Executor
        get() = coroutineScheduler

    private var coroutineScheduler = createScheduler()

    private fun createScheduler() =
        CoroutineScheduler(corePoolSize, maxPoolSize, idleWorkerKeepAliveNs, schedulerName)

   //... 생략
}
```

#### **`Dispatchers.IO`**
   - I/O 작업(네트워크, 파일)에 최적화.
   - 많은 스레드를 사용하는 풀에서 실행.
   - 스레드 풀 크기 : 64개 또는 CPU 코어 갯수가 64보다 크다면 CPU 코어 갯수
   - Dispatchers.Default와 스레드풀을 내부적으로 공유함
[quote]
____
This dispatcher and its views share threads with the Default dispatcher, so using withContext(Dispatchers.IO) { ... } when already running on the Default dispatcher typically does not lead to an actual switching to another thread. In such scenarios, the underlying implementation attempts to keep the execution on the same thread on a best-effort basis.

As a result of thread sharing, more than 64 (default parallelism) threads can be created (but not used) during operations over IO dispatcher.

출처 : https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-dispatchers/-i-o.html
____

#### **`Dispatchers.Main`**
   - 메인 스레드에서 실행.
   - 만약 해당 디스페처에서 블로킹 작업을 실행할시 메인 스레드가 블로킹 됨

#### **`Dispatchers.Unconfined`**
   - 특정 스레드에 바인딩되지 않음.
   - 테스트나 간단한 작업에 사용.

#### **커스텀 디스패처**
   - `Executors` 등을 이용해 직접 생성.
   - 특정 요구사항에 맞는 실행 환경 구성.

**사용 예시**: 
- CPU 작업 → `Default`
- I/O 작업 → `IO`
`withContext`로 디스패처 변경 가능.

**주의**
limitedParallelism(n)함수 호출시 호출한 디스페쳐의 내부값을 변경하는 것이 아닌 기존 디스페쳐의 설정을 이어받은 `LimitedDispatcher`를 새로 생성해서 리턴한다.
즉 limitedParallelism(n)를 통해 디스페쳐를 생성한 후에 결과를 사용해야한다.

---

[[section-202412-22일]]
22일
===
### Redis가 빠른 이유

1. **인메모리 기반**  
   - 레디스는 데이터를 디스크가 아닌 메모리에 저장한다.  
   - 메모리는 디스크보다 접근 속도가 훨씬 빠르기 때문에, 데이터 읽기/쓰기 작업이 매우 빠르게 처리된다.  
   - 다만, 이로 인해 데이터 셋의 크기는 사용 가능한 메모리 용량에 의해 제한된다.

2. **I/O 멀티플렉싱**  
   - 레디스는 epoll과 같은 I/O 멀티플렉싱 기법을 사용하여 다수의 클라이언트 연결을 단일 스레드에서 효율적으로 처리한다.

3. **싱글 쓰레드 기반**  
   - 레디스는 기본적으로 싱글 쓰레드로 동작하여 스레드 간의 컨텍스트 스위칭 비용이 없다.  
   - 동시성 문제에서도 자유롭다.  

   그러나 **레디스 6.0**부터는 **I/O 작업에 한해서 멀티스레딩이 적용**되었다:  
   - 클라이언트가 전송한 명령을 네트워크로 읽고 파싱하는 부분  
   - 명령 처리 결과 메시지를 네트워크로 클라이언트에 전달하는 부분  
   이를 통해 네트워크 작업 효율성이 향상되었지만, 명령 처리 로직은 여전히 싱글 쓰레드 기반으로 동작한다.  

같이 읽으면 좋은글 : https://velog.io/@redjen/%EB%A0%88%EB%94%94%EC%8A%A4%EB%8A%94-%EC%99%9C-%EB%B9%A0%EB%A5%BC%EA%B9%8C

---

[[section-202412-23일]]
23일
===
### epoll 내부 동작 방식

1. epoll 객체 생성:
**Red-Black Tree** (RB-Tree): 등록된 파일 디스크립터(FD)를 관리하는 데 사용됩니다. 이 구조는 FD를 효율적으로 추가, 삭제, 검색할 수 있도록 설계되었습니다.
**Ready List**: RB-Tree에 등록된 FD 중에서 이벤트가 발생한 FD를 별도로 관리하는 리스트입니다. 이 구조는 이벤트 발생 시 epoll_wait가 빠르게 반환될 수 있도록 돕습니다.
추가적으로, Ready List는 링크드 리스트로 구현되며, 이미 Ready List에 추가된 FD는 중복해서 추가되지 않는 특징이 있습니다.

2. epoll에 FD 등록:
epoll_ctl은 FD를 추가(ADD), 수정(MOD), 삭제(DEL)하는 데 사용됩니다.
FD를 등록하면 RB-Tree에 추가됩니다. 등록 시, FD에 감시할 이벤트 타입(예: 읽기 가능, 쓰기 가능, 에러 발생 등)을 지정합니다.
이 단계에서는 Ready List는 여전히 비어 있습니다. 이벤트가 발생하기 전까지 FD는 Ready List로 이동하지 않습니다.

3. 유저 애플리케이션은 Ready List를 감시:
epoll_wait를 호출하면 Ready List에 이벤트가 발생한 FD가 있는지 확인합니다.
Ready List에 항목이 없으면 애플리케이션은 지정된 타임아웃 시간 동안 블록되거나, 타임아웃이 없을 경우 계속 대기(sleep) 상태에 있습니다.
Ready List에 이벤트가 발생한 FD가 있으면, 해당 FD가 반환됩니다.

4. 이벤트 발생(네트워크 예시): 
네트워크 카드 드라이버에서 데이터 수신하면, NIC(Network Interface Card)가 데이터를 메모리로 DMA(Direct Memory Access)를 통해 전달합니다.
이후 커널의 네트워크 스택이 데이터를 처리하며, FD의 소켓 버퍼에 데이터를 저장하고 해당 FD가 Ready List로 이동됩니다.

5. FD를 Ready List로 이동:
소켓 버퍼에 데이터가 기록되거나 FD에 지정된 이벤트 조건(예: 쓰기 가능)이 만족되면 커널은 FD를 Ready List로 이동시킵니다.
Ready List는 FD와 이벤트 정보를 포함하며, epoll_wait가 호출될 때 반환될 준비 상태가 됩니다.

6. 유저 애플리케이션이 Ready List 확인:
epoll_wait가 Ready List의 FD를 반환하면, 애플리케이션은 FD를 사용해 데이터를 읽거나 처리합니다.
FD가 이벤트 처리를 완료한 후에도 조건이 계속 만족되면, FD는 다시 Ready List에 남아 있을 수 있습니다. 이 경우, 중복 처리를 방지하기 위해 애플리케이션에서 추가 처리가 필요할 수 있습니다.

#### epoll의 2가지 모드

* Edge-Triggered (ET)
상태 변화(예: 데이터 도착)가 발생한 순간 한 번만 Ready List에 FD가 추가됩니다.
** 특징: 이벤트가 발생한 후 추가 상태 변화가 없으면, Ready List에 다시 추가되지 않습니다.
데이터가 남아 있더라도 FD는 다시 반환되지 않으므로, 데이터를 모두 읽거나 써야 합니다.
** 적합한 사용 사례:
고성능 요구 환경. 사용자 애플리케이션이 즉각적으로 처리하고 반복적으로 확인하지 않아도 되는 경우.

* Level-Triggered (LT) 모드
FD가 "읽기 가능" 또는 "쓰기 가능" 상태로 유지되는 동안, Ready List에 계속 FD가 추가됩니다.
** 특징:
데이터를 완전히 처리하지 않으면, 다음 epoll_wait 호출 시 같은 FD가 반복적으로 반환됩니다.
모든 데이터를 철저히 읽거나 써야 불필요한 중복 반환이 방지됩니다.
** 적합한 사용 사례:
단순하고 신뢰성 있는 처리를 원하는 경우. 애플리케이션이 데이터를 한 번에 처리하지 못할 수도 있는 경우.

TMI : 레디스는 Edge-Triggered 모드를 사용한다.
TMI2 : fd의 의미
**fd(file descriptor)**는 커널에서 네트워크 소켓이나 파일을 식별하는 고유한 번호이다.
fd 자체는 데이터를 포함하지 않지만, 이를 통해 소켓이나 파일에서 데이터를 읽거나 쓸 수 있다.
(Java에서는 fd를 추상화한 소켓 객체를 통해 데이터를 InputStream 또는 Channel 등을 사용하여 읽거나 쓸 수 있다.)

---


